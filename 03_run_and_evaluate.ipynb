{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8860961",
   "metadata": {},
   "source": [
    "# EcoHome Energy Advisor - Agent Run & Evaluation\n",
    "\n",
    "In this notebook, you'll run the Energy Advisor agent with various real-world scenarios and see how it helps customers optimize their energy usage.\n",
    "\n",
    "## Learning Objectives\n",
    "- Create the agent's instructions\n",
    "- Run the Energy Advisor with different types of questions\n",
    "- Evaluate response quality and accuracy\n",
    "- Measure tool usage effectiveness\n",
    "- Identify areas for improvement\n",
    "- Implement evaluation metrics\n",
    "\n",
    "## Evaluation Criteria\n",
    "- **Accuracy**: Correct information and calculations\n",
    "- **Relevance**: Responses address the user's question\n",
    "- **Completeness**: Comprehensive answers with actionable advice\n",
    "- **Tool Usage**: Appropriate use of available tools\n",
    "- **Reasoning**: Clear explanation of recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6ffc7d",
   "metadata": {},
   "source": [
    "## 1. Import and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b989c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d063734",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent instructions\n",
    "\n",
    "ECOHOME_SYSTEM_PROMPT = \"\"\"\n",
    "You are EcoHome, a proactive residential energy advisor for homeowners and renters.\n",
    "Role: deliver actionable, data-backed recommendations that reduce costs and improve energy efficiency.\n",
    "\n",
    "Steps to follow:\n",
    "1) Clarify location, timeframe, and devices if missing; state any assumptions.\n",
    "2) Pull relevant data using tools: weather for solar/thermal context, electricity prices for time-of-use windows, usage and solar history for trends, recent summary when timeframe is unclear, and energy tips for best practices.\n",
    "3) Analyze patterns (peaks, off-peak windows, forecasted conditions) and decide the best actions.\n",
    "4) Quantify impact (kWh and USD) with calculate_energy_savings when numbers are available; otherwise give conservative ranges.\n",
    "5) Present 2-4 prioritized recommendations with reasoning and next steps; note gaps and ask one concise follow-up question if needed.\n",
    "\n",
    "Key capabilities:\n",
    "- get_weather_forecast: assess upcoming conditions and solar potential.\n",
    "- get_electricity_prices: identify off-peak vs peak hours for load shifting.\n",
    "- query_energy_usage / query_solar_generation: inspect historical consumption and production.\n",
    "- get_recent_energy_summary: get a quick view when the user provides little context.\n",
    "- search_energy_tips: retrieve best practices via RAG.\n",
    "- calculate_energy_savings: quantify savings for proposed actions.\n",
    "\n",
    "Recommendations guidance:\n",
    "- Tie every suggestion to retrieved data (price periods, forecast, usage patterns) and make them specific and time-bound.\n",
    "- Prefer scheduling and load shifting to cheaper hours; suggest thermostat, EV, appliance, and solar-usage tweaks.\n",
    "- Include expected savings and assumptions; provide quick wins plus one longer-term improvement when relevant.\n",
    "- If data is missing, state the assumption and request the needed detail succinctly.\n",
    "\n",
    "Example questions you handle:\n",
    "- \"Given this week's forecast, when should I run my dishwasher to save the most?\"\n",
    "- \"How can I cut my EV charging costs in San Diego tomorrow?\"\n",
    "- \"Review my past 7 days of usage and suggest ways to reduce peak load.\"\n",
    "- \"Compare my solar generation last week to expected weather and give optimizations.\"\n",
    "\n",
    "Respond concisely, show key tool findings briefly, then deliver the final plan.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1aaa54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecohome_agent = Agent(\n",
    "    instructions=ECOHOME_SYSTEM_PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a63a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ecohome_agent.invoke(\n",
    "    question=\"When should I charge my electric car tomorrow to minimize cost and maximize solar power?\",\n",
    "    context=\"Location: San Francisco, CA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "429e43cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Summary of Findings\n",
      "\n",
      "1. **Weather Forecast for Tomorrow (October 7, 2023)**:\n",
      "   - The day is expected to be **cloudy** with no significant solar irradiance throughout the day. Solar generation is likely to be minimal.\n",
      "\n",
      "2. **Electricity Prices**:\n",
      "   - **Off-Peak Rates**: \n",
      "     - 12 AM - 5 AM: $0.077 - $0.085 per kWh\n",
      "     - 10 PM - 11 PM: $0.082 - $0.084 per kWh\n",
      "   - **Peak Rates**:\n",
      "     - 6 AM - 9 PM: $0.155 - $0.165 per kWh\n",
      "\n",
      "3. **EV Usage Data**:\n",
      "   - No recent data was available for your EV usage from October 1 to October 6, indicating either no charging or no recorded usage.\n",
      "\n",
      "### Recommendations\n",
      "\n",
      "Given the forecast and pricing data, here are the prioritized recommendations for charging your electric vehicle (EV) tomorrow:\n",
      "\n",
      "1. **Charge During Off-Peak Hours**:\n",
      "   - **Best Time**: Charge your EV between **12 AM - 5 AM** or **10 PM - 11 PM** when the rates are lowest (as low as $0.077 per kWh).\n",
      "   - **Reasoning**: Charging during these hours will minimize costs significantly compared to peak hours.\n",
      "\n",
      "2. **Avoid Charging During Peak Hours**:\n",
      "   - **Peak Hours**: Avoid charging between **6 AM - 9 PM** when rates are higher (up to $0.165 per kWh).\n",
      "   - **Reasoning**: Charging during peak hours can lead to higher costs without the benefit of solar energy.\n",
      "\n",
      "3. **Consider Charging Overnight**:\n",
      "   - If you can, set your EV to charge overnight. This will ensure you take advantage of the lowest rates and avoid any potential peak charges.\n",
      "\n",
      "### Expected Savings\n",
      "- **Assuming a charge of 10 kWh**:\n",
      "  - **Off-Peak Cost**: $0.077 * 10 kWh = $0.77\n",
      "  - **Peak Cost**: $0.165 * 10 kWh = $1.65\n",
      "  - **Savings**: Charging during off-peak hours could save you approximately **$0.88** per 10 kWh compared to peak hours.\n",
      "\n",
      "### Next Steps\n",
      "- Set your EV to charge during the recommended off-peak hours.\n",
      "- Monitor your usage to gather data for future optimizations.\n",
      "\n",
      "If you have any specific charging capacity or preferences, please let me know!\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0aa3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOLS:\n",
      "- None detected\n"
     ]
    }
   ],
   "source": [
    "print(\"TOOLS:\")\n",
    "tool_names = []\n",
    "for msg in response[\"messages\"]:\n",
    "    # Collect tool names from structured tool_calls (OpenAI-style)\n",
    "    if getattr(msg, \"tool_calls\", None):\n",
    "        for tc in msg.tool_calls:\n",
    "            func = (tc or {}).get(\"function\", {})\n",
    "            name = func.get(\"name\")\n",
    "            if name:\n",
    "                tool_names.append(name)\n",
    "    # Collect from additional kwargs if present\n",
    "    payload = getattr(msg, \"additional_kwargs\", {}) or {}\n",
    "    for tc in (payload.get(\"tool_calls\") or []):\n",
    "        func = (tc or {}).get(\"function\", {})\n",
    "        name = func.get(\"name\")\n",
    "        if name:\n",
    "            tool_names.append(name)\n",
    "    fc = payload.get(\"function_call\") or getattr(msg, \"function_call\", None)\n",
    "    if isinstance(fc, dict) and fc.get(\"name\"):\n",
    "        tool_names.append(fc[\"name\"])\n",
    "    # Collect from ToolMessage or legacy function message types\n",
    "    if hasattr(msg, \"dict\"):\n",
    "        d = msg.dict()\n",
    "        if d.get(\"type\") in {\"tool\", \"function\"} and d.get(\"name\"):\n",
    "            tool_names.append(d[\"name\"])\n",
    "\n",
    "if tool_names:\n",
    "    for name in tool_names:\n",
    "        print(\"-\", name)\n",
    "else:\n",
    "    print(\"- None detected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d2730e",
   "metadata": {},
   "source": [
    "## 2. Define Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aefe0d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive scenario-based test cases for the Energy Advisor\n",
    "# Covers EV charging, thermostat, appliance scheduling, solar usage, and cost savings calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f086892",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    {\n",
    "        \"id\": \"ev_charging_peak_avoid\",\n",
    "        \"question\": \"When should I charge my EV tomorrow to avoid peak rates and use my rooftop solar?\",\n",
    "        \"expected_tools\": [\"get_electricity_prices\", \"get_weather_forecast\"],\n",
    "        \"expected_response\": \"Should recommend off-peak/night or mid-day solar window with rate comparison and solar hours.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"ev_charging_weekend_home\",\n",
    "        \"question\": \"It's the weekend and I'll be home all day. What is the cheapest charging window for my EV?\",\n",
    "        \"expected_tools\": [\"get_electricity_prices\", \"get_weather_forecast\"],\n",
    "        \"expected_response\": \"Should highlight weekend pricing profile and suggest a 2-3 hour window with solar alignment.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"thermostat_heatwave_peak\",\n",
    "        \"question\": \"How should I set my thermostat this afternoon during a heatwave to stay comfortable but minimize cost?\",\n",
    "        \"expected_tools\": [\"get_weather_forecast\", \"get_electricity_prices\", \"search_energy_tips\"],\n",
    "        \"expected_response\": \"Should suggest pre-cooling before peak, target temp band, and ventilation/humidity tips.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"thermostat_night_setback\",\n",
    "        \"question\": \"What night-time thermostat setpoints save money without overcooling while I sleep?\",\n",
    "        \"expected_tools\": [\"get_electricity_prices\", \"search_energy_tips\"],\n",
    "        \"expected_response\": \"Should give a setback range, reference off-peak pricing, and comfort guidance.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"laundry_offpeak\",\n",
    "        \"question\": \"When should I run my laundry tomorrow to minimize electricity cost?\",\n",
    "        \"expected_tools\": [\"get_electricity_prices\", \"search_energy_tips\"],\n",
    "        \"expected_response\": \"Should recommend an off-peak window and mention load shifting benefits.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"dishwasher_solar_midday\",\n",
    "        \"question\": \"I want to run the dishwasher using my solar. What time window is best tomorrow?\",\n",
    "        \"expected_tools\": [\"get_weather_forecast\", \"get_electricity_prices\", \"query_solar_generation\"],\n",
    "        \"expected_response\": \"Should pick a sunny mid-day slot referencing solar output and any peak price overlap.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"solar_self_consumption\",\n",
    "        \"question\": \"How do I maximize solar self-consumption tomorrow afternoon to reduce grid draw?\",\n",
    "        \"expected_tools\": [\"get_weather_forecast\", \"query_solar_generation\", \"get_recent_energy_summary\"],\n",
    "        \"expected_response\": \"Should suggest shifting flexible loads into high-irradiance hours with expected kWh impact.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"ev_vs_public_charger_savings\",\n",
    "        \"question\": \"How much do I save charging my EV at home off-peak versus a public charger at $0.35/kWh?\",\n",
    "        \"expected_tools\": [\"calculate_energy_savings\", \"get_electricity_prices\"],\n",
    "        \"expected_response\": \"Should compute $/kWh delta, show savings per session, and yearly projection.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"thermostat_savings_delta\",\n",
    "        \"question\": \"Estimate the savings if I raise my cooling setpoint by 2°F for 8 hours a day.\",\n",
    "        \"expected_tools\": [\"calculate_energy_savings\", \"search_energy_tips\"],\n",
    "        \"expected_response\": \"Should quantify kWh and $ savings with the adjusted setpoint assumption.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"daily_schedule_combo\",\n",
    "        \"question\": \"Give me a day schedule for EV charging, dishwasher, and dryer to minimize cost and use solar.\",\n",
    "        \"expected_tools\": [\"get_electricity_prices\", \"get_weather_forecast\", \"get_recent_energy_summary\", \"search_energy_tips\"],\n",
    "        \"expected_response\": \"Should provide a staggered schedule with peak avoidance and solar-aware timing per device.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "if len(test_cases) < 10:\n",
    "    raise ValueError(\"You MUST have at least 10 test cases\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cdde81",
   "metadata": {},
   "source": [
    "## 3. Run Agent Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8eb83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = \"Location: San Francisco, CA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc82e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running Agent Tests ===\n",
      "\n",
      "Test 1: ev_charging_peak_avoid\n",
      "Question: When should I charge my EV tomorrow to avoid peak rates and use my rooftop solar?\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the agent tests\n",
    "# For each test case, call the agent and collect the response\n",
    "# Store results for evaluation\n",
    "\n",
    "print(\"=== Running Agent Tests ===\")\n",
    "test_results = []\n",
    "\n",
    "for i, test_case in enumerate(test_cases):\n",
    "    print(f\"\\nTest {i+1}: {test_case['id']}\")\n",
    "    print(f\"Question: {test_case['question']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Call the agent\n",
    "        response = ecohome_agent.invoke(\n",
    "            question=test_case['question'],\n",
    "            context=CONTEXT\n",
    "        )\n",
    "        \n",
    "        # Store the result\n",
    "        result = {\n",
    "            'test_id': test_case['id'],\n",
    "            'question': test_case['question'],\n",
    "            'response': response,\n",
    "            'expected_tools': test_case['expected_tools'],\n",
    "            'expected_response': test_case['expected_response'],\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        test_results.append(result)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        result = {\n",
    "            'test_id': test_case['id'],\n",
    "            'question': test_case['question'],\n",
    "            'response': f\"Error: {str(e)}\",\n",
    "            'expected_tools': test_case['expected_tools'],\n",
    "            'expected_response': test_case['expected_response'],\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'error': str(e)\n",
    "        }\n",
    "        test_results.append(result)\n",
    "\n",
    "print(f\"\\nCompleted {len(test_results)} tests\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be9f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760814c",
   "metadata": {},
   "source": [
    "## 4. Evaluate Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_response(question, final_response, expected_response):\n",
    "    \"\"\"Evaluate a single response against expected response\"\"\"\n",
    "    import re\n",
    "    from difflib import SequenceMatcher\n",
    "\n",
    "    def _normalize(text):\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        return re.sub(r\"\\s+\", \" \", text.strip().lower())\n",
    "\n",
    "    def _tokens(text):\n",
    "        return set(re.findall(r\"\\b\\w+\\b\", _normalize(text)))\n",
    "\n",
    "    def _coverage(base_tokens, comparison_tokens):\n",
    "        if not base_tokens:\n",
    "            return 0.0\n",
    "        return len(base_tokens & comparison_tokens) / len(base_tokens)\n",
    "\n",
    "    normalized_final = _normalize(final_response)\n",
    "    normalized_expected = _normalize(expected_response)\n",
    "\n",
    "    question_tokens = _tokens(question)\n",
    "    final_tokens = _tokens(final_response)\n",
    "    expected_tokens = _tokens(expected_response)\n",
    "\n",
    "    accuracy = SequenceMatcher(None, normalized_expected, normalized_final).ratio() if (normalized_expected or normalized_final) else 0.0\n",
    "    relevance = _coverage(question_tokens, final_tokens)\n",
    "    completeness = _coverage(expected_tokens, final_tokens)\n",
    "    usefulness = max(0.0, min(1.0, (0.3 * accuracy) + (0.3 * relevance) + (0.4 * completeness)))\n",
    "\n",
    "    def _describe(score, aspect):\n",
    "        if score >= 0.85:\n",
    "            return f\"Strong {aspect}\"\n",
    "        if score >= 0.6:\n",
    "            return f\"Moderate {aspect}\"\n",
    "        return f\"Weak {aspect}\"\n",
    "\n",
    "    strengths = []\n",
    "    improvement_areas = []\n",
    "    if completeness >= 0.7:\n",
    "        strengths.append(\"Covers most of the expected points.\")\n",
    "    else:\n",
    "        improvement_areas.append(\"Add missing key details from the expected answer.\")\n",
    "    if relevance >= 0.7:\n",
    "        strengths.append(\"Response stays focused on the question.\")\n",
    "    else:\n",
    "        improvement_areas.append(\"Tighten the answer to better address the user's question.\")\n",
    "    if accuracy >= 0.7:\n",
    "        strengths.append(\"Wording aligns well with expected content.\")\n",
    "    else:\n",
    "        improvement_areas.append(\"Adjust phrasing to better match the expected response.\")\n",
    "\n",
    "    feedback = {\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"relevance\": relevance,\n",
    "            \"completeness\": completeness,\n",
    "            \"usefulness\": usefulness,\n",
    "        },\n",
    "        \"summaries\": {\n",
    "            \"accuracy\": _describe(accuracy, \"accuracy\"),\n",
    "            \"relevance\": _describe(relevance, \"relevance\"),\n",
    "            \"completeness\": _describe(completeness, \"completeness\"),\n",
    "            \"usefulness\": _describe(usefulness, \"usefulness\"),\n",
    "        },\n",
    "        \"strengths\": strengths,\n",
    "        \"improvements\": improvement_areas,\n",
    "        \"notes\": {\n",
    "            \"missing_expected_terms\": list(expected_tokens - final_tokens),\n",
    "            \"extra_response_terms\": list(final_tokens - expected_tokens),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0dc154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tool_usage(messages, expected_tools):\n",
    "    \"\"\"Evaluate if the right tools were used\"\"\"\n",
    "    expected_set = {t.lower() for t in (expected_tools or [])}\n",
    "    used_tools = set()\n",
    "\n",
    "    def _extract_from_message(msg_obj):\n",
    "        \"\"\"Pull tool names from various message shapes.\"\"\"\n",
    "        record = None\n",
    "        if hasattr(msg_obj, \"dict\"):\n",
    "            record = msg_obj.dict()\n",
    "        elif isinstance(msg_obj, dict):\n",
    "            record = msg_obj\n",
    "        if not record:\n",
    "            return []\n",
    "\n",
    "        names = []\n",
    "        # Direct function/tool message\n",
    "        for key in (\"name\",):\n",
    "            if record.get(\"type\") in {\"function\", \"tool\"} and record.get(key):\n",
    "                names.append(record[key])\n",
    "        # OpenAI-style tool_calls\n",
    "        additional = record.get(\"additional_kwargs\", {}) or {}\n",
    "        for tc in additional.get(\"tool_calls\", []) or []:\n",
    "            func = (tc or {}).get(\"function\", {})\n",
    "            if func.get(\"name\"):\n",
    "                names.append(func[\"name\"])\n",
    "        # Nested function_call pattern\n",
    "        func_call = record.get(\"function_call\", {}) or {}\n",
    "        if func_call.get(\"name\"):\n",
    "            names.append(func_call[\"name\"])\n",
    "        return names\n",
    "\n",
    "    for msg in messages or []:\n",
    "        for name in _extract_from_message(msg):\n",
    "            used_tools.add(name.lower())\n",
    "\n",
    "    overlap = used_tools & expected_set\n",
    "    missing = expected_set - used_tools\n",
    "    unexpected = used_tools - expected_set\n",
    "\n",
    "    appropriateness = len(overlap) / len(used_tools) if used_tools else 0.0\n",
    "    completeness = len(overlap) / len(expected_set) if expected_set else 1.0\n",
    "\n",
    "    def _describe(score, aspect):\n",
    "        if score >= 0.85:\n",
    "            return f\"Strong {aspect}\"\n",
    "        if score >= 0.6:\n",
    "            return f\"Moderate {aspect}\"\n",
    "        return f\"Weak {aspect}\"\n",
    "\n",
    "    strengths = []\n",
    "    improvements = []\n",
    "    if overlap:\n",
    "        strengths.append(f\"Used expected tools: {sorted(overlap)}\")\n",
    "    if not missing:\n",
    "        strengths.append(\"All required tools were invoked.\")\n",
    "    else:\n",
    "        improvements.append(f\"Missing tools: {sorted(missing)}\")\n",
    "    if unexpected:\n",
    "        improvements.append(f\"Unexpected tools used: {sorted(unexpected)}\")\n",
    "\n",
    "    feedback = {\n",
    "        \"metrics\": {\n",
    "            \"tool_appropriateness\": appropriateness,\n",
    "            \"tool_completeness\": completeness,\n",
    "        },\n",
    "        \"summaries\": {\n",
    "            \"tool_appropriateness\": _describe(appropriateness, \"tool appropriateness\"),\n",
    "            \"tool_completeness\": _describe(completeness, \"tool completeness\"),\n",
    "        },\n",
    "        \"strengths\": strengths,\n",
    "        \"improvements\": improvements,\n",
    "        \"details\": {\n",
    "            \"expected\": sorted(expected_set),\n",
    "            \"used\": sorted(used_tools),\n",
    "            \"missing_expected\": sorted(missing),\n",
    "            \"unexpected_used\": sorted(unexpected),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3df271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall scores and metrics\n",
    "# Identify strengths and weaknesses\n",
    "# Provide recommendations for improvement\n",
    "def generate_evaluation_report(test_results):\n",
    "    \"\"\"Aggregate per-test evaluations into a structured report.\"\"\"\n",
    "    from datetime import datetime\n",
    "\n",
    "    report = {\n",
    "        \"generated_at\": datetime.now().isoformat(),\n",
    "        \"overall\": {},\n",
    "        \"per_test\": [],\n",
    "        \"strengths\": [],\n",
    "        \"weaknesses\": [],\n",
    "        \"recommendations\": [],\n",
    "    }\n",
    "\n",
    "    aggregates = {\n",
    "        \"accuracy\": 0.0,\n",
    "        \"relevance\": 0.0,\n",
    "        \"completeness\": 0.0,\n",
    "        \"usefulness\": 0.0,\n",
    "        \"tool_appropriateness\": 0.0,\n",
    "        \"tool_completeness\": 0.0,\n",
    "    }\n",
    "\n",
    "    def _get_final_message(msgs):\n",
    "        if not msgs:\n",
    "            return \"\"\n",
    "        last = msgs[-1]\n",
    "        if hasattr(last, \"content\"):\n",
    "            return last.content or \"\"\n",
    "        if isinstance(last, dict):\n",
    "            return last.get(\"content\", \"\")\n",
    "        return str(last)\n",
    "\n",
    "    for result in test_results or []:\n",
    "        messages = result.get(\"response\", {}).get(\"messages\", []) if isinstance(result.get(\"response\"), dict) else []\n",
    "        final_response = _get_final_message(messages)\n",
    "\n",
    "        response_eval = evaluate_response(\n",
    "            result.get(\"question\", \"\"),\n",
    "            final_response,\n",
    "            result.get(\"expected_response\", \"\"),\n",
    "        )\n",
    "        tool_eval = evaluate_tool_usage(messages, result.get(\"expected_tools\", []))\n",
    "\n",
    "        test_entry = {\n",
    "            \"test_id\": result.get(\"test_id\"),\n",
    "            \"question\": result.get(\"question\"),\n",
    "            \"response_preview\": (final_response or \"\").strip()[:280],\n",
    "            \"response_metrics\": response_eval,\n",
    "            \"tool_metrics\": tool_eval,\n",
    "        }\n",
    "        report[\"per_test\"].append(test_entry)\n",
    "\n",
    "        for key in aggregates:\n",
    "            aggregates[key] += (\n",
    "                response_eval[\"metrics\"].get(key, 0.0)\n",
    "                if key in response_eval[\"metrics\"]\n",
    "                else tool_eval[\"metrics\"].get(key, 0.0)\n",
    "            )\n",
    "\n",
    "        tagged_strengths = [f\"[{result.get('test_id')}] {s}\" for s in response_eval.get(\"strengths\", [])]\n",
    "        tagged_strengths += [f\"[{result.get('test_id')}] {s}\" for s in tool_eval.get(\"strengths\", [])]\n",
    "        tagged_improvements = [f\"[{result.get('test_id')}] {s}\" for s in response_eval.get(\"improvements\", [])]\n",
    "        tagged_improvements += [f\"[{result.get('test_id')}] {s}\" for s in tool_eval.get(\"improvements\", [])]\n",
    "        \n",
    "        report[\"strengths\"].extend(tagged_strengths)\n",
    "        report[\"weaknesses\"].extend(tagged_improvements)\n",
    "\n",
    "    total_tests = max(len(report[\"per_test\"]), 1)\n",
    "    overall_metrics = {k: v / total_tests for k, v in aggregates.items()}\n",
    "    report[\"overall\"] = overall_metrics\n",
    "\n",
    "    recommendations = []\n",
    "    if overall_metrics.get(\"completeness\", 0) < 0.7:\n",
    "        recommendations.append(\"Increase coverage of expected answer points; ensure key facts are included.\")\n",
    "    if overall_metrics.get(\"relevance\", 0) < 0.7:\n",
    "        recommendations.append(\"Tighten responses to directly address the user's question and avoid drift.\")\n",
    "    if overall_metrics.get(\"tool_completeness\", 0) < 0.8:\n",
    "        recommendations.append(\"Invoke all required tools per scenario; add guardrails for missing calls.\")\n",
    "    if overall_metrics.get(\"tool_appropriateness\", 0) < 0.8:\n",
    "        recommendations.append(\"Prefer expected tools and avoid unnecessary calls; refine tool selection logic.\")\n",
    "    if overall_metrics.get(\"accuracy\", 0) < 0.7:\n",
    "        recommendations.append(\"Align phrasing and facts with expected responses; adjust templating or prompts.\")\n",
    "    if not recommendations:\n",
    "        recommendations.append(\"Maintain current approach; consider stress-testing with harder edge cases.\")\n",
    "    report[\"recommendations\"] = recommendations\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "def display_evaluation_report(report):\n",
    "    \"\"\"Pretty-print the evaluation report with clear sectioning.\"\"\"\n",
    "    if not report:\n",
    "        print(\"No report to display.\")\n",
    "        return\n",
    "\n",
    "    def _section(title):\n",
    "        print(\"\\n\" + title)\n",
    "        print(\"-\" * len(title))\n",
    "\n",
    "    def _fmt_tagged(item):\n",
    "        if isinstance(item, str) and item.startswith(\"[\") and \"]\" in item:\n",
    "            end = item.find(\"]\")\n",
    "            test_id = item[1:end]\n",
    "            text = item[end+1:].strip()\n",
    "            return f\"[{test_id}] {text}\"\n",
    "        return item\n",
    "\n",
    "    def _print_list(title, items):\n",
    "        _section(title)\n",
    "        if items:\n",
    "            for item in items:\n",
    "                print(f\"- {_fmt_tagged(item)}\")\n",
    "        else:\n",
    "            print(\"- None noted\")\n",
    "\n",
    "    print(\"=== Evaluation Report ===\")\n",
    "    print(f\"Generated at: {report.get('generated_at')}\")\n",
    "\n",
    "    overall = report.get(\"overall\", {})\n",
    "    _section(\"Overall Metrics\")\n",
    "    for k in (\"accuracy\", \"relevance\", \"completeness\", \"usefulness\", \"tool_appropriateness\", \"tool_completeness\"):\n",
    "        if k in overall:\n",
    "            print(f\"- {k}: {overall[k]:.2f}\")\n",
    "\n",
    "    _print_list(\"Key Strengths\", report.get(\"strengths\", []))\n",
    "    _print_list(\"Key Weaknesses\", report.get(\"weaknesses\", []))\n",
    "    _print_list(\"Recommendations\", report.get(\"recommendations\", []))\n",
    "\n",
    "    _section(\"Per-Test Breakdown\")\n",
    "    for entry in report.get(\"per_test\", []):\n",
    "        print(f\"\\nTest: {entry.get('test_id')} — {entry.get('question')}\")\n",
    "        print(f\"Response preview: {entry.get('response_preview')}\")\n",
    "        rm = entry.get(\"response_metrics\", {}).get(\"metrics\", {})\n",
    "        tm = entry.get(\"tool_metrics\", {}).get(\"metrics\", {})\n",
    "        print(\"  Response metrics:\")\n",
    "        for k in (\"accuracy\", \"relevance\", \"completeness\", \"usefulness\"):\n",
    "            if k in rm:\n",
    "                print(f\"    - {k}: {rm[k]:.2f}\")\n",
    "        print(\"  Tool metrics:\")\n",
    "        for k in (\"tool_appropriateness\", \"tool_completeness\"):\n",
    "            if k in tm:\n",
    "                print(f\"    - {k}: {tm[k]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = generate_evaluation_report(test_results)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a005c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_evaluation_report(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68b4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
